[{"id":"betteragent","user_id":"3ca28d73-ca39-4820-a53b-271ff73ee58f","name":"BetterAgent","type":"pipe","content":"import json\nfrom fastapi import Request\nfrom pydantic import BaseModel, Field\nfrom open_webui.models.users import Users\nfrom open_webui.utils.chat import generate_chat_completion\n\nDEFAULT_REFINEMENT_PROMPT = \"\"\"{\n  \"prompt\":\"\\\\n# Prompt Analyst and Optimizer System\\\\nYou are an expert prompt analyst and rewriter tasked with optimizing user prompts before they\\'re routed to the most suitable AI model. Your analysis ensures users receive the highest quality responses by matching their needs with the most appropriate model from hundreds available.\\\\n    \\\\n## Core Analysis Framework\\\\nWhen a user submits a prompt, thoroughly analyze it across these dimensions:\\\\n    \\\\n### Task Type Assessment\\\\n- Identify the primary task category (creative writing, factual information, programming, problem-solving, etc.)\\\\n- Determine if it involves multiple sub-tasks or stages\\\\n- Assess the domain knowledge required (general, specialized technical field, creative domain)\\\\n\\\\n### Cognitive Complexity Evaluation\\\\n- Determine reasoning depth required (simple recall, multi-step problem solving, creative ideation)\\\\n- Assess whether specialized thinking patterns are needed (mathematical, logical, creative, empathetic)\\\\n- Identify if specific methodologies should be applied (scientific analysis, design thinking, etc.)\\\\n\\\\n### User Intent Inference\\\\n- Look beyond explicit requests to understand the underlying user need\\\\n- Identify unstated requirements that would make a response truly valuable\\\\n- Determine if the user has implied any constraints or preferences\\\\n- Consider what level of detail would best serve their purpose\\\\n\\\\n### Optimal Output Determination\\\\n- Format requirements (narrative, structured list, code blocks, tables, step-by-step guide)\\\\n- Style considerations (formal/technical, conversational, instructional, creative)\\\\n- Length and depth expectations (concise summary vs. comprehensive analysis)\\\\n- Visual or structural elements that would enhance comprehension\\\\n\\\\n### Model Capability Matching\\\\n- Assess which model strengths would best address this specific request\\\\n- Consider if the task requires up-to-date knowledge, specialized domain expertise, or strong reasoning\\\\n\\\\n## Prompt Rewriting Guidelines\\\\nTransform the user\\'s original prompt using these techniques:\\\\n\\\\n### Structural Enhancement\\\\n- Add clear role assignments when beneficial (\\\\\"As an expert in [domain]...\\\\\")\\\\n- Provide explicit context the original prompt may lack\\\\n- Break complex requests into sequential steps\\\\n- Use markdown formatting for clarity and organization\\\\n- Implement XML tags to clearly define components for complex tasks\\\\n\\\\n### Content Clarification\\\\n- Specify expected output format and structure\\\\n- Add parameters for length, style, and depth\\\\n- Include examples or templates when helpful\\\\n- Establish clear evaluation criteria for the response\\\\n- Define scope boundaries to focus the model\\'s attention\\\\n\\\\n### Reasoning Guidance\\\\n- For complex problems, incorporate chain-of-thought prompting\\\\n- Request explicit reasoning steps when appropriate\\\\n- Add self-verification instructions for fact-checking\\\\n- Include perspective-taking for nuanced topics\\\\n\\\\n## Your Response Format\\\\nFor each user prompt you receive, provide:\\\\n```markdown\\\\n# Prompt Analysis\\\\n## Task Classification\\\\n[Identify primary task type, complexity level, and relevant domains]\\\\n## User Intent\\\\n[Describe what you believe the user is ultimately trying to accomplish]\\\\n## Optimal Response Characteristics\\\\n[Specify ideal format, style, structure, and components]\\\\n# Rewritten Prompt\\\\n[Your optimized prompt using appropriate structure and best practices]\\\\n# Optimization Rationale\\\\n[Brief explanation of key changes made and how they improve the prompt]\\\\n```\\\\n\\\\nAlways preserve the core objective of the user\\'s request while enhancing clarity, specificity, and structure to get the best possible response.\\\\n\"\n}\"\"\"\n\n\nclass Pipe:\n    class Valves(BaseModel):\n        DEFAULT_ROUTING_MODEL: str = Field(\n            default=\"gpt-4o-mini-2024-07-18\",\n            description=\"The default model to use for routing and prompt refinement.\",\n        )\n        GENERAL_MESSAGE_REFINEMENT_PROMPT: str = Field(\n            default=DEFAULT_REFINEMENT_PROMPT,\n            description=\"The default prompt to use for message refinement.\",\n        )\n        AVAILABLE_MODELS_SCHEMA: str = Field(\n            default='{\"models\":{\"gpt-3.5-turbo\":{\"description\":\"A versatile and cost-effective model, well-suited for daily tasks including conversation, text generation, and summarization. It is faster and cheaper than GPT-4.\"},\"gpt-3.5-turbo-16k\":{\"description\":\"Similar to GPT-3.5-turbo but supports longer conversations and larger prompts (up to 16K tokens). Ideal for detailed exchanges or more complex prompts with extended context.\"},\"gpt-4\":{\"description\":\"Excellent for complex tasks requiring advanced reasoning, creative problem-solving, or in-depth understanding. More expensive but offers superior analytical and linguistic capabilities.\"},\"gpt-4-32k\":{\"description\":\"Comparable to GPT-4 but with a significantly larger token limit (32K). Great for handling extensive documents or very long inputs.\"},\"text-davinci-003\":{\"description\":\"The most capable GPT-3 model, ideal for tasks involving creative writing, detailed reasoning, and instructive prompts. Often used for text generation or complex transformations.\"},\"code-davinci-002\":{\"description\":\"A specialized variant of the GPT-3.5 family with a strong focus on code generation and completion. Well-suited for writing, refactoring, or explaining code in multiple languages.\"},\"text-curie-001\":{\"description\":\"A mid-range GPT-3 model balancing capability and speed. Useful for moderate tasks where velocity is a priority over maximum complexity.\"},\"text-babbage-001\":{\"description\":\"A simpler GPT-3 model suited for straightforward classification, parsing, or basic text tasks. It\\'s more cost-effective than Curie.\"},\"text-ada-001\":{\"description\":\"The smallest and fastest base GPT-3 model, best for very light tasks like quick classification, minimal text transformations, or prototyping.\"},\"o1-2024-12-17\":{\"description\":\"A specialized model for advanced reasoning tasks, particularly suited for math or science problems. Emphasizes logic, coherence, and thorough exploration.\"},\"o3-2024-12-17\":{\"description\":\"An advanced iteration of the O-series, built for creative and innovative content generation. Good at brainstorming, storytelling, and generating new ideas.\"}}}',\n            description=\"A JSON object representing the available models and information for how to use them.\",\n        )\n\n    def __init__(self):\n        self.valves = self.Valves()\n\n    def pipes(self):\n        return [\n            {\"id\": \"better_agent\", \"name\": \"BetterAgent\"},\n        ]\n\n    async def pipe(\n        self,\n        body: dict,\n        __user__: dict,\n        __request__: Request,\n    ) -> str:\n        user = Users.get_user_by_id(__user__[\"id\"])\n\n        last_message = body[\"messages\"][-1][\"content\"]\n\n        model_and_refined_message_dict = await self.best_model_with_prompt_updates(\n            __request__, user, last_message\n        )\n\n        body[\"model\"] = model_and_refined_message_dict[\"best_suited_model\"]\n\n        body[\"messages\"][-1][\"content\"] = model_and_refined_message_dict[\n            \"refined_message\"\n        ]\n\n        return await generate_chat_completion(__request__, body, user)\n\n    async def best_model_with_prompt_updates(self, request, user, user_message: str):\n        enabled_models = request.app.state.MODELS\n\n        all_available_models = json.loads(self.valves.AVAILABLE_MODELS_SCHEMA)[\"models\"]\n\n        enabled_and_available_models = {\n            key: all_available_models[key]\n            for key in enabled_models.keys()\n            if key in all_available_models\n        }\n\n        messages = [\n            {\n                \"role\": \"system\",\n                \"content\": json.loads(self.valves.GENERAL_MESSAGE_REFINEMENT_PROMPT)[\n                    \"prompt\"\n                ],\n            },\n            {\n                \"role\": \"system\",\n                \"content\": \"Here are the available models and their descriptions:\\n\\n\"\n                + \"\\n\".join(\n                    [\n                        f\"- {model}: {details['description']}\"\n                        for model, details in enabled_and_available_models.items()\n                    ]\n                ),\n            },\n            {\n                \"role\": \"user\",\n                \"content\": f\"Please choose the best model and then refine and clarify the following message:\\n\\n{user_message}\",\n            },\n        ]\n\n        body = {\n            \"model\": self.valves.DEFAULT_ROUTING_MODEL,\n            \"messages\": messages,\n            \"stream\": False,\n            \"response_format\": {\n                \"type\": \"json_schema\",\n                \"json_schema\": {\n                    \"name\": \"response\",\n                    \"schema\": {\n                        \"type\": \"object\",\n                        \"properties\": {\n                            \"best_suited_model\": {\n                                \"type\": \"string\",\n                                \"description\": \"The model best suited for the user's request.\",\n                                \"enum\": list(enabled_and_available_models.keys()),\n                            },\n                            \"refined_message\": {\n                                \"type\": \"string\",\n                                \"description\": \"A refined version of the message.\",\n                            },\n                        },\n                        \"required\": [\"best_suited_model\", \"refined_message\"],\n                    },\n                },\n            },\n        }\n\n        response = await generate_chat_completion(request, body, user)\n\n        return json.loads(response[\"choices\"][0][\"message\"][\"content\"])\n","meta":{"description":"A better agent","manifest":{}},"is_active":true,"is_global":false,"updated_at":1741717397,"created_at":1741704257}]